{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso Procesamiento Imágenes - Sentimientos\n",
    "\n",
    "El maching learning nos permite realizar aprendizajes automáticos con muchos fines. En este caso vamos a utilizar las marcas faciales y un algoritmo de machine learning para ver si podemos predecir las emociones y sentimientos de una persona a partir de su imagen.\n",
    "\n",
    "**¿Qué objetivos tienes este caso?**\n",
    "\n",
    "Como vimos en clase, este tipo de algoritmo es la base para el reconocimiento facial en dispositivos móviles o sistemas de reconocimiento en cajeros para detectar sentimiento como por ejemplo en robos... Tiene diferentes utilidades tanto en el sector de la ciberseguridad como en otros sectores. \n",
    "\n",
    "Este algoritmo, a partir de una base de datos de imágenes, detecta los puntos principales por sentimiento para, en la foto o imagen de entrada (o en la realizad en la cámara con imagen en tiempo real), detecte cual de los sentimientos pertenece a esta. En este ejemplo, para que veáis los diferentes resultados he incorporado los diferentes valores por sentimiento en la foto resultante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importamos las librerías necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, glob, random, math, numpy as np, dlib\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos nuestra lista de sentimientos. Estos son los que el algoritmo buscará en la base de datos de imágenes para realizar el estudio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\"miedo\", \"feliz\", \"neutral\", \"tristeza\", \"sorpresa\", \"enfado\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el [Clahe](http://amroamroamro.github.io/mexopencv/opencv/clahe_demo_gui.html) (ecualización de histogramas). Los utilizaremos para mejorar el contraste de nuestras imágenes.\n",
    "\n",
    "**Definimos el detector y predictor de marcas faciales**\n",
    "Este programa de ejemplo muestra cómo encontrar rostros humanos frontales en una imagen y estimar su pose. La pose toma la forma de 68 puntos de referencia. Estos son puntos en la cara, como las esquinas de la boca, a lo largo de las cejas, en los ojos, etc. \n",
    "\n",
    "**Support vector machines (SVM)**\n",
    "#Establecemos el SVM en clasificador como un vector de apoyo de máquinas polinomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") \n",
    "clf = SVC(kernel='linear', probability=True, tol=1e-3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos 3 funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_files(emotion)**  \n",
    "En esta función lo que realizaresmos es seleccionar la carpeta donde se encuentran las diferentes carpetas de emociones, ordenamos la lista de ficheros con  random.shuffle() y seleccionamos la imagen en la que vamos a realizar la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(emotion):\n",
    "    files = glob.glob(\"dataset/%s/*\" %emotion)\n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files))] \n",
    "    prediction=['dataset/2.png'] #Se añade la imagen que queremos procesar\n",
    "    return training, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es leer el conjunto de datos existente en un conjunto de entrenamiento y predicción con las etiquetas correspondientes, entrenar al clasificador (utilizamos máquinas de vectores de soporte con kernel lineal de SKLearn), y evaluar el resultado. Esta evaluación se realizará en dos pasos; Primero, obtenemos una precisión general después de diez vueltas de bucle de segmentación, entrenamiento y predicción de datos diferentes, y luego evaluaremos las probabilidades predictivas.\n",
    "  \n",
    "**get_landmarks(image)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image):\n",
    "   detections = detector(image, 1)\n",
    "   for k,d in enumerate(detections): #Para todas las cara detectadas de forma individual\n",
    "      shape = predictor(image, d) # Dibuja puntos de referencia faciales con la clase predictor\n",
    "      xlist = []\n",
    "      ylist = []\n",
    "      for i in range(1,68): #Guarda coordenadas X e Y en dos listas\n",
    "          xlist.append(float(shape.part(i).x))\n",
    "          ylist.append(float(shape.part(i).y))\n",
    " \n",
    "      xmean = np.mean(xlist) #Obtiene la media de ambos ejes para determinar el centro de gravedad\n",
    "      ymean = np.mean(ylist)\n",
    "      xcentral = [(x-xmean) for x in xlist] #Calcula distancia entre cada punto y el punto central en ambos ejes\n",
    "      ycentral = [(y-ymean) for y in ylist]\n",
    "\n",
    "      if xlist[26] == xlist[29]: #Si la coordenada x del conjunto son las mismas, el ángulo es 0,  evitamos el error 'divide by 0' en la función\n",
    "          anglenose = 0\n",
    "      else:\n",
    "          anglenose = int(math.atan((ylist[26]-ylist[29])/(xlist[26]-xlist[29]))*180/math.pi)\n",
    "\n",
    "      if anglenose < 0:\n",
    "          anglenose += 90\n",
    "      else:\n",
    "          anglenose -= 90\n",
    "\n",
    "      #Guardamos todos los puntos de referencia      \n",
    "      landmarks_vectorised = []\n",
    "      for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):\n",
    "          landmarks_vectorised.append(x)\n",
    "          landmarks_vectorised.append(y)\n",
    "          meannp = np.asarray((ymean,xmean))\n",
    "          coornp = np.asarray((z,w))\n",
    "          dist = np.linalg.norm(coornp-meannp)\n",
    "          anglerelative = (math.atan((z-ymean)/(w-xmean))*180/math.pi) - anglenose\n",
    "          landmarks_vectorised.append(dist)\n",
    "          landmarks_vectorised.append(anglerelative)\n",
    "\n",
    "   if len(detections) < 1: \n",
    "       landmarks_vectorised = \"error\"\n",
    "   return landmarks_vectorised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**make_sets()**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sets():\n",
    "  training_data = []\n",
    "  training_labels = []\n",
    "  prediction_data = []\n",
    "  prediction_labels = []\n",
    "  training = []\n",
    "  prediction = []\n",
    "  for emotion in emotions:\n",
    "      training, prediction = get_files(emotion) #Agrega los datos a la lista de entrenamiento y predicción, y genera etiquetas 0-7\n",
    "      for item in training:\n",
    "          image = cv2.imread(item) #Abrimos la imagen\n",
    "          gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #Convertimos a escala de grises\n",
    "          clahe_image = clahe.apply(gray)\n",
    "          landmarks_vectorised = get_landmarks(clahe_image)\n",
    "          if landmarks_vectorised == \"error\":\n",
    "              pass\n",
    "          else:\n",
    "             training_data.append(landmarks_vectorised) #Vector de imágenes a la lista de datos de entrenamiento\n",
    "             training_labels.append(emotions.index(emotion))\n",
    "\n",
    "      for item in prediction: #Repetir el proceso anterior para el conjunto de predicciones\n",
    "          image = cv2.imread(item)\n",
    "          gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "          clahe_image = clahe.apply(gray)\n",
    "          landmarks_vectorised = get_landmarks(clahe_image)\n",
    "          if landmarks_vectorised == \"error\":\n",
    "              pass\n",
    "          else:\n",
    "             prediction_data.append(landmarks_vectorised)\n",
    "             prediction_labels.append(emotions.index(emotion))\n",
    "\n",
    "  return training_data, training_labels, prediction_data, prediction_labels,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Programa principal**  \n",
    "En este apartado mostramos el resto del programa principal. En esta parte del código lo que se realiza es el bucle de repetición para generar los sets y generar las estimaciones.   \n",
    "En la segunda parte obtenemos los puntos, los redondeamos y grabamos el resultado en la imagen con el resultado del procesado de la imangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando sets 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandromagdalenanino/Anaconda/anaconda3/envs/data/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento SVM linear 0\n",
      "Obteniendo precisiones 0\n",
      "linear:  0.2\n",
      "proba:  [[0.38901529 0.02853662 0.10621226 0.09946772 0.37676811]\n",
      " [0.38901529 0.02853662 0.10621226 0.09946772 0.37676811]\n",
      " [0.38901529 0.02853662 0.10621226 0.09946772 0.37676811]\n",
      " [0.38901529 0.02853662 0.10621226 0.09946772 0.37676811]\n",
      " [0.38901529 0.02853662 0.10621226 0.09946772 0.37676811]]\n",
      "Generando sets 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandromagdalenanino/Anaconda/anaconda3/envs/data/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento SVM linear 1\n",
      "Obteniendo precisiones 1\n",
      "linear:  0.2\n",
      "proba:  [[0.26071177 0.01655507 0.07555648 0.13030882 0.51686787]\n",
      " [0.26071177 0.01655507 0.07555648 0.13030882 0.51686787]\n",
      " [0.26071177 0.01655507 0.07555648 0.13030882 0.51686787]\n",
      " [0.26071177 0.01655507 0.07555648 0.13030882 0.51686787]\n",
      " [0.26071177 0.01655507 0.07555648 0.13030882 0.51686787]]\n",
      "Generando sets 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandromagdalenanino/Anaconda/anaconda3/envs/data/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento SVM linear 2\n",
      "Obteniendo precisiones 2\n",
      "linear:  0.2\n",
      "proba:  [[0.30323612 0.01644113 0.09210006 0.11928777 0.46893492]\n",
      " [0.30323612 0.01644113 0.09210006 0.11928777 0.46893492]\n",
      " [0.30323612 0.01644113 0.09210006 0.11928777 0.46893492]\n",
      " [0.30323612 0.01644113 0.09210006 0.11928777 0.46893492]\n",
      " [0.30323612 0.01644113 0.09210006 0.11928777 0.46893492]]\n",
      "Generando sets 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandromagdalenanino/Anaconda/anaconda3/envs/data/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento SVM linear 3\n",
      "Obteniendo precisiones 3\n",
      "linear:  0.2\n",
      "proba:  [[0.27925164 0.02287114 0.0798745  0.13146601 0.4865367 ]\n",
      " [0.27925164 0.02287114 0.0798745  0.13146601 0.4865367 ]\n",
      " [0.27925164 0.02287114 0.0798745  0.13146601 0.4865367 ]\n",
      " [0.27925164 0.02287114 0.0798745  0.13146601 0.4865367 ]\n",
      " [0.27925164 0.02287114 0.0798745  0.13146601 0.4865367 ]]\n",
      "Generando sets 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandromagdalenanino/Anaconda/anaconda3/envs/data/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento SVM linear 4\n",
      "Obteniendo precisiones 4\n",
      "linear:  0.2\n",
      "proba:  [[0.39703955 0.03221025 0.0889161  0.11699016 0.36484394]\n",
      " [0.39703955 0.03221025 0.0889161  0.11699016 0.36484394]\n",
      " [0.39703955 0.03221025 0.0889161  0.11699016 0.36484394]\n",
      " [0.39703955 0.03221025 0.0889161  0.11699016 0.36484394]\n",
      " [0.39703955 0.03221025 0.0889161  0.11699016 0.36484394]]\n",
      "Generando sets 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandromagdalenanino/Anaconda/anaconda3/envs/data/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento SVM linear 5\n",
      "Obteniendo precisiones 5\n",
      "linear:  0.2\n",
      "proba:  [[0.43535425 0.02789622 0.0913908  0.08906209 0.35629664]\n",
      " [0.43535425 0.02789622 0.0913908  0.08906209 0.35629664]\n",
      " [0.43535425 0.02789622 0.0913908  0.08906209 0.35629664]\n",
      " [0.43535425 0.02789622 0.0913908  0.08906209 0.35629664]\n",
      " [0.43535425 0.02789622 0.0913908  0.08906209 0.35629664]]\n",
      "Generando sets 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandromagdalenanino/Anaconda/anaconda3/envs/data/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento SVM linear 6\n",
      "Obteniendo precisiones 6\n",
      "linear:  0.2\n",
      "proba:  [[0.27844371 0.02294403 0.07588875 0.11285828 0.50986524]\n",
      " [0.27844371 0.02294403 0.07588875 0.11285828 0.50986524]\n",
      " [0.27844371 0.02294403 0.07588875 0.11285828 0.50986524]\n",
      " [0.27844371 0.02294403 0.07588875 0.11285828 0.50986524]\n",
      " [0.27844371 0.02294403 0.07588875 0.11285828 0.50986524]]\n",
      "Generando sets 7\n"
     ]
    }
   ],
   "source": [
    "probam1 = np.zeros((5,10))\n",
    "probam2 = np.zeros((1,5))\n",
    "\n",
    "accur_lin = []\n",
    "\n",
    "for i in range(0,10):\n",
    "  print(\"Generando sets %s\" %i) #Hace un muestreo aleatorio 80/20%\n",
    "  training_data, training_labels, prediction_data, prediction_labels = make_sets()\n",
    "\n",
    "  npar_train = np.array(training_data) #Gira el conjunto de entrenamiento en una matriz numpy para el clasificador\n",
    "  npar_trainlabs = np.array(training_labels)\n",
    "  print(\"Entrenamiento SVM linear %s\" %i) #Entrenamiento SVM\n",
    "  clf.fit(npar_train, training_labels)\n",
    "\n",
    "  print(\"Obteniendo precisiones %s\" %i) #Utilice la función score () para obtener mayor precisión\n",
    "  npar_pred = np.array(prediction_data)\n",
    "  pred_lin = clf.score(npar_pred, prediction_labels)\n",
    "  print (\"linear: \", pred_lin)\n",
    "  accur_lin.append(pred_lin) #Guarda la precision en una lista\n",
    "  proba=clf.predict_proba(prediction_data) #Genera las estimaciones de probabilidad\n",
    "  print (\"proba: \", proba)\n",
    "  probam1[:,i]=proba[1,:]\n",
    "  probam2=proba[1,:]+probam2\n",
    "\n",
    "\n",
    " \n",
    "proba=probam2/10 \n",
    "p1=round(proba[0,0],2)\n",
    "p2=round(proba[0,1],2)\n",
    "p3=round(proba[0,2],2)\n",
    "p4=round(proba[0,3],2)\n",
    "print(\"Valor medio lin svm: %.3f\" %np.mean(accur_lin)) #Hacemos 10 ejecuciones para aumentar precision\n",
    "\n",
    "frame=cv2.imread('dataset/2.png') #Aqui se añade la imagen que quieres procesar pero aqui solo se carga para el resultado final\n",
    "#ploteamos el resultado\n",
    "cv2.putText(frame, \"Miedo: {}\".format(p1), (10, 30),\n",
    " cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "cv2.putText(frame, \"Feliz: {:.2f}\".format(p2), (10, 60),\n",
    " cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "cv2.putText(frame, \"Neutral: {}\".format(p3), (10, 90),\n",
    " cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "cv2.putText(frame, \"Triste: {:.2f}\".format(p4), (10, 120),\n",
    " cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    " \n",
    "\n",
    " #Mostramos la imagen\n",
    "cv2.imshow(\"Ventana de resultado\", frame)\n",
    "cv2.imwrite('resultado.png',frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
